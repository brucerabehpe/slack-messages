{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "standing-berry",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lilmac/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-8d7de7a15afc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLancasterStemmer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtextblob\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvaderSentiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvaderSentiment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "# import basic libraries \n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer, PorterStemmer\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "\n",
    "# read csv\n",
    "df = pd.read_csv('../data/data_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-speaking",
   "metadata": {},
   "source": [
    "### Sentiment in new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "suitable-pontiac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_name</th>\n",
       "      <th>user</th>\n",
       "      <th>real_name</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>reply_users_count</th>\n",
       "      <th>replies_true</th>\n",
       "      <th>day_name</th>\n",
       "      <th>day_type</th>\n",
       "      <th>...</th>\n",
       "      <th>month</th>\n",
       "      <th>reactions_count</th>\n",
       "      <th>link_of_file</th>\n",
       "      <th>files_true</th>\n",
       "      <th>link_of_attachments</th>\n",
       "      <th>attachments_true</th>\n",
       "      <th>reaction_true</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>general</td>\n",
       "      <td>U01S79YDELR</td>\n",
       "      <td>Karina Condeixa</td>\n",
       "      <td>hang told add educ</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>...</td>\n",
       "      <td>May</td>\n",
       "      <td>0</td>\n",
       "      <td>nofile</td>\n",
       "      <td>False</td>\n",
       "      <td>nolink</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>general</td>\n",
       "      <td>U01S79YDELR</td>\n",
       "      <td>Karina Condeixa</td>\n",
       "      <td>improv score ad metric achiev use synonym stro...</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>...</td>\n",
       "      <td>May</td>\n",
       "      <td>0</td>\n",
       "      <td>nofile</td>\n",
       "      <td>False</td>\n",
       "      <td>nolink</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>general</td>\n",
       "      <td>U01RRV4JX6Z</td>\n",
       "      <td>Francisco Ebeling</td>\n",
       "      <td>feel like slave dumb resum word algorithm simp...</td>\n",
       "      <td>261</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>...</td>\n",
       "      <td>May</td>\n",
       "      <td>0</td>\n",
       "      <td>nofile</td>\n",
       "      <td>False</td>\n",
       "      <td>nolink</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(-0.0875, 0.35)</td>\n",
       "      <td>-0.0875</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  channel_name         user          real_name  \\\n",
       "0      general  U01S79YDELR    Karina Condeixa   \n",
       "1      general  U01S79YDELR    Karina Condeixa   \n",
       "2      general  U01RRV4JX6Z  Francisco Ebeling   \n",
       "\n",
       "                                                text  text_length  \\\n",
       "0                                 hang told add educ           35   \n",
       "1  improv score ad metric achiev use synonym stro...           98   \n",
       "2  feel like slave dumb resum word algorithm simp...          261   \n",
       "\n",
       "   reply_count  reply_users_count  replies_true day_name day_type  ... month  \\\n",
       "0            0                  0         False   Sunday  Weekend  ...   May   \n",
       "1            0                  0         False   Sunday  Weekend  ...   May   \n",
       "2           31                  2          True   Sunday  Weekend  ...   May   \n",
       "\n",
       "   reactions_count link_of_file  files_true link_of_attachments  \\\n",
       "0                0       nofile       False              nolink   \n",
       "1                0       nofile       False              nolink   \n",
       "2                0       nofile       False              nolink   \n",
       "\n",
       "   attachments_true reaction_true        sentiment  polarity subjectivity  \n",
       "0             False         False       (0.0, 0.0)    0.0000         0.00  \n",
       "1             False         False       (0.0, 0.0)    0.0000         0.00  \n",
       "2             False         False  (-0.0875, 0.35)   -0.0875         0.35  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the descriptions into textblob\n",
    "post_blob = [TextBlob(desc) for desc in df['text']]\n",
    "#add the sentiment metrics to the dataframe\n",
    "df['polarity'] = [b.sentiment.polarity for b in post_blob]\n",
    "df['subjectivity'] = [b.sentiment.subjectivity for b in post_blob]\n",
    "#show dataframe\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "advanced-timing",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SentimentIntensityAnalyzer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-084a1eac6586>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#load VADER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0manalyzer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#Add VADER metrics to dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compound'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compound'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'neg'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'neg'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SentimentIntensityAnalyzer' is not defined"
     ]
    }
   ],
   "source": [
    "# load VADER\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "# add VADER metrics to dataframe\n",
    "df['compound'] = [analyzer.polarity_scores(v)['compound'] for v in df['text']]\n",
    "df['neg'] = [analyzer.polarity_scores(v)['neg'] for v in df['text']]\n",
    "df['neu'] = [analyzer.polarity_scores(v)['neu'] for v in df['text']]\n",
    "df['pos'] = [analyzer.polarity_scores(v)['pos'] for v in df['text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-column",
   "metadata": {},
   "source": [
    "### Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "thirty-origin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'feel like slave dumb resume worded algorithm simply doesnt like format chose stick lean one column cv imagine future much serious decisions made algorithms serious flaws like'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the text type to string\n",
    "df['text'] = df['text'].astype(str)\n",
    "\n",
    "# before lowercasing \n",
    "df['text'][2]\n",
    "\n",
    "# lowercase all reviews\n",
    "df['text'] = df['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "df['text'][2] ## to see the difference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "operating-laugh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'feel like slave dumb resume worded algorithm simply doesnt like format chose stick lean one column cv imagine future much serious decisions made algorithms serious flaws like'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove punctuation\n",
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text\n",
    "df['text'] = df['text'].apply(remove_punctuations)\n",
    "df['text'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "electronic-cardiff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'feel like slave dumb resume worded algorithm simply doesnt like format chose stick lean one column cv imagine future much serious decisions made algorithms serious flaws like'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stopwords\n",
    "stop = stopwords.words('english')\n",
    "df['text'] = df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "df['text'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "rational-binding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'feel like slave dumb resum word algorithm simpli doesnt like format chose stick lean one column cv imagin futur much seriou decis made algorithm seriou flaw like'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stemming\n",
    "st = PorterStemmer()\n",
    "df['text'] = df['text'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
    "df['text'][2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "tender-litigation",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-1cde942a3724>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstopwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOPWORDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "stopwords = set(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "major-interview",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'WordCloud' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-63b9bd40b1da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mshow_wordcloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-88-63b9bd40b1da>\u001b[0m in \u001b[0;36mshow_wordcloud\u001b[0;34m(col, title)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshow_wordcloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     wordcloud = WordCloud(\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mbackground_color\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'white'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mstopwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmax_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'WordCloud' is not defined"
     ]
    }
   ],
   "source": [
    "def show_wordcloud(col, title = None):\n",
    "    wordcloud = WordCloud(\n",
    "        background_color='white',\n",
    "        stopwords=stopwords,\n",
    "        max_words=500,\n",
    "        max_font_size=40, \n",
    "        scale=3,\n",
    "        random_state=1\n",
    "    ).generate(str(col))\n",
    "\n",
    "    fig = plt.figure(1, figsize=(14, 14))\n",
    "    plt.axis('off')\n",
    "    if title: \n",
    "        fig.suptitle(title, fontsize=20)\n",
    "        fig.subplots_adjust(top=2.3)\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    show_wordcloud(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-israel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
